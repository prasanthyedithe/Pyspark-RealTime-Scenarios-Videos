# Pyspark-RealTime-Scenarios-Videos

Pyspark Scenarios 1: How to create partition by month and year in pyspark 
https://lnkd.in/dFfxYR_F
 
Pyspark scenarios 2 : how to read variable number of columns data in pyspark dataframe 
https://lnkd.in/drsTGNCC

Pyspark Scenarios 3 : how to skip first few rows from data file in pyspark
https://lnkd.in/d3yczciE

Pyspark Scenarios 4 : how to remove duplicate rows in pyspark dataframe  https://lnkd.in/djq68Mn6

Pyspark Scenarios 5 : how read all files from nested folder in pySpark dataframe 
https://lnkd.in/d6wRqqr8

Pyspark Scenarios 6 How to Get no of rows from each file in pyspark dataframe 
https://lnkd.in/gV7CqnfW

Pyspark Scenarios 7 : how to get no of rows at each partition in pyspark dataframe 
https://lnkd.in/gDdHmZPS

Pyspark Scenarios 8: How to add Sequence generated surrogate key as a column in dataframe. 
https://lnkd.in/d2-uN6_E

Pyspark Scenarios 9 : How to get Individual column wise null records count
https://lnkd.in/d-C4keZC

Pyspark Scenarios 10:Why we should not use crc32 for Surrogate Keys Generation? 
https://lnkd.in/d6eqqCD9

Pyspark Scenarios 11 : how to handle double delimiter or multi delimiters in pyspark 
https://lnkd.in/dme8vvnC

Pyspark Scenarios 12 : how to get 53 week number years in pyspark extract 53rd week number in spark
https://lnkd.in/gUv3j9Gy

Pyspark Scenarios 13 : how to handle complex json data file in pyspark 
https://lnkd.in/d6KCTdW7

Pyspark Scenarios 14 : How to implement Multiprocessing in Azure Databricks 
https://lnkd.in/gzUkrm8X

Pyspark Scenarios 15 : how to take table ddl backup in databricks 
https://lnkd.in/dMim9ESK

Pyspark Scenarios 16: Convert pyspark string to date format issue dd-mm-yy old format 
https://lnkd.in/gHwbkbJp

Pyspark Scenarios 17 : How to handle duplicate column errors in delta table
https://lnkd.in/gDV7CfAB

Pyspark Scenarios 18 : How to Handle Bad Data in pyspark dataframe using pyspark schema
https://lnkd.in/gfptFuMx

Pyspark Scenarios 19 : difference between OrderBy Sort and sortWithinPartitions Transformations
https://lnkd.in/gW9TQmWt

Pyspark Scenarios 20 : difference between coalesce and repartition in pyspark
https://lnkd.in/gjstBAdG

Pyspark Scenarios 21 : Dynamically processing complex json file in pyspark
https://lnkd.in/giWz9ebW

Pyspark Scenarios 22 : How To create data files based on the number of rows in PySpark
https://lnkd.in/g27ZP7bM

Pyspark Scenarios 23 : How do I select a column name with spaces in PySpark?
https://lnkd.in/g2gP8Rhy
